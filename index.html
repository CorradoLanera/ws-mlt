<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Artificial Intelligence and Machine Learning in Supporting Clinical Decision</title>
    <meta charset="utf-8" />
    <meta name="author" content="CorradoLanera" />
    <script src="index_files/header-attrs-2.22/header-attrs.js"></script>
    <link href="index_files/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <script src="index_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="index_files/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="index_files/shareon-1.4.1/shareon.min.js"></script>
    <link href="index_files/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="index_files/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="index_files/panelset-0.2.6/panelset.js"></script>
    <link href="index_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"xbb001e2f25f4a5a93b0eae2c4b8644f","expires":1}</script>
    <script src="index_files/himalaya-1.1.0/himalaya.js"></script>
    <script src="index_files/js-cookie-3.0.0/js.cookie.js"></script>
    <link href="index_files/editable-0.2.6/editable.css" rel="stylesheet" />
    <script src="index_files/editable-0.2.6/editable.js"></script>
    <script src="index_files/fabric-4.3.1/fabric.min.js"></script>
    <link href="index_files/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="index_files/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
    <meta name="description" content="Introduction to Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="generator" content="xaringan and remark.js"/>
    <meta name="github-repo" content="CorradoLanera/ws-mlt"/>
    <meta name="twitter:title" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="twitter:description" content="Introduction to Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="twitter:url" content="https://CorradoLanera.github.io/ws-mlt"/>
    <meta name="twitter:image" content="https://github.com/CorradoLanera/ws-mlt/raw/main/img/cover.jpg"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:creator" content="@CorradoLanera"/>
    <meta name="twitter:site" content="@CorradoLanera"/>
    <meta property="og:title" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta property="og:description" content="Introduction to Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta property="og:url" content="https://CorradoLanera.github.io/ws-mlt"/>
    <meta property="og:image" content="https://github.com/CorradoLanera/ws-mlt/raw/main/img/cover.jpg"/>
    <meta property="og:type" content="website"/>
    <meta property="og:locale" content="en_US"/>
    <meta property="article:author" content="UBEP"/>
    <link href="index_files/countdown-0.4.0/countdown.css" rel="stylesheet" />
    <script src="index_files/countdown-0.4.0/countdown.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle, bg_title, hide-count


&lt;img src="img/logo_800anni.png" width="150px"/&gt;
&lt;img src="img/DSCTV.png" width="50px"/&gt;
&lt;img src="img/UBEP.png" width="50px"/&gt;
&lt;img src="img/LAIMS.png" width="50px"/&gt;




<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #0051BA;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>

<style>.shareagain-bar {
--shareagain-foreground: rgb(255, 255, 255);
--shareagain-background: rgba(0, 0, 0, 0.5);
--shareagain-facebook: none;
--shareagain-pinterest: none;
--shareagain-reddit: none;
}</style>




&lt;style type="text/css"&gt;
.left-code {
  color: #777;
  width: 38%;
  height: 92%;
  float: left;
}
.right-code {
  color: #777;
  width: 55%;
  height: 92%;
  float: right;
  padding-top: 0.5em;
}
.left-plot {
  width: 43%;
  float: left;
}
.right-plot {
  width: 60%;
  float: right;
}
.hide-count .remark-slide-number {
  display: none;
}

.bg_title {
  position: relative;
  z-index: 1;
}

.bg_title::before {    
      content: "";
      background-image: url('img/bg1.png');
      background-size: contain;
      position: absolute;
      top: 0px;
      right: 0px;
      bottom: 0px;
      left: 0px;
      opacity: 0.3;
      z-index: -1;
}

&lt;/style&gt;





&lt;br&gt;
# Introduction to &lt;br&gt;**.orange[How] Machine .orange[Learning]**&lt;br&gt;and **Artificial .orange[Intelligence]** can&lt;br&gt;**Support Clinical .orange[Decision]**

Slide at: https://CorradoLanera.github.io/ws-mlt  
&lt;img src="img/bit.ly_ws-mlt.png" width="12%" /&gt;
&lt;br&gt;

**Biostatistics Seminar** - Padova, 2023/06/05 -

Scuola di SpecialitÃ  in Fisica Medica --- University of Padova

Corrado Lanera | [**Unit of Biostatistics, Epidemiology, and Public Health**](https://www.unipd-ubep.it/)



---
class: hide-count
.panelset[
.panel[.panel-name[Code]

```r
# The downloaded csv with graph data of your PubMed query
pmlt_path &lt;- here("data/PubMed_Timeline_Results_by_Year.csv")

pmlt_path |&gt; 
  read_csv(skip = 1L) |&gt;  # The first line is the query!
  ggplot(aes(x = Year, y = Count)) + 
  geom_point() +
  geom_label(
    aes(label = glue::glue("Total = {sum(Count)}")),
    x = 1995,
    y = 3000
  ) +
  labs(
    title = "Historical progression of MLT/AI papers in \"your\" field",
# The first line is the query :-)
    caption = read_lines(pmlt_path, n_max = 1)
  )
```



]

.panel[.panel-name[Output]

&lt;img src="index_files/figure-html/unnamed-chunk-3-1.png" width="100%" /&gt;

]
]



---
class: inverse, hide-count
# What we are going to see

Purpose of this seminar is to introducing **.orange[what is]** Machine Learning, why/in what is different from other (statistical) tools, how to understand (and **.orange[trust]**!) it's results, and looking at **.orange[some example]** and **.orange[best practice]** in conducing a machine learning project.

&lt;br&gt;
&lt;br&gt;

My principal aim is to let you able to start **.orange[understanding]** (and **.orange[evaluating]** the quality!) of a machine learning project when used for clinical purposes.

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

**.orange[Promise]: I do not show you any (other) R code ðŸ˜‡**


---
class: hide-count
# .orange[Acknowledgement]

The following slides and their contents were produced thanks to the preciuos work of .orange[**Paola Berchialla**] (UniTo/DSCB)

.center[
&lt;img src="img/thankyou-robot.jpg" width="50%" /&gt;
]


---
class: inverse, bottom, right, hide-count


&lt;img src="img/profilo_CL.jpg" width="50%" /&gt;
# Find me at...


[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg>](https://www.unipd-ubep.it/) [**www.unipd-ubep.it**](https://www.unipd-ubep.it/)

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/UBESP-DCTV)
**@UBESP-DCTV**

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>](https://twitter.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>](https://telegram.me/CorradoLanera)
**@CorradoLanera**

[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M128 0C110.3 0 96 14.3 96 32V224h96V192c0-35.3 28.7-64 64-64H480V32c0-17.7-14.3-32-32-32H128zM256 160c-17.7 0-32 14.3-32 32v32h96c35.3 0 64 28.7 64 64V416H576c17.7 0 32-14.3 32-32V192c0-17.7-14.3-32-32-32H256zm240 64h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16H496c-8.8 0-16-7.2-16-16V240c0-8.8 7.2-16 16-16zM64 256c-17.7 0-32 14.3-32 32v13L187.1 415.9c1.4 1 3.1 1.6 4.9 1.6s3.5-.6 4.9-1.6L352 301V288c0-17.7-14.3-32-32-32H64zm288 84.8L216 441.6c-6.9 5.1-15.3 7.9-24 7.9s-17-2.8-24-7.9L32 340.8V480c0 17.7 14.3 32 32 32H320c17.7 0 32-14.3 32-32V340.8z"/></svg>](mailto:Corrado.Lanera@ubep.unipd.it) [**Corrado.Lanera**__.orange[@ubep.unipd.it]__](mailto:Corrado.Lanera@ubep.unipd.it)

[<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M128 0c13.3 0 24 10.7 24 24V64H296V24c0-13.3 10.7-24 24-24s24 10.7 24 24V64h40c35.3 0 64 28.7 64 64v16 48V448c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V192 144 128C0 92.7 28.7 64 64 64h40V24c0-13.3 10.7-24 24-24zM400 192H48V448c0 8.8 7.2 16 16 16H384c8.8 0 16-7.2 16-16V192zM329 297L217 409c-9.4 9.4-24.6 9.4-33.9 0l-64-64c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0l47 47 95-95c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9z"/></svg>](https://calendly.com/corradolanera) [**calendly.com/corradolanera**](https://calendly.com/corradolanera)

---
class: inverse, middle
# .center[**.orange[Overview]**]

- .orange[**Overview**]: what does it means "Machine Learning"?

- .orange[**Classifiers**]

- Model .orange[**selection**] and .orange[**evaluation**]

- .orange[**Neural Networks**] and .orange[**Deep Learning**]

- A Machine Learning .orange[**usecase**] project in healthcare

- .orange[**Best practices**] for implementing Machine Learning








---
class: inverse, middle, center, hide-count
# .orange[Overview]

What does it means "Machine Learning"?




---
# .orange[What is **Machine Learning**]
  

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    Machine Learning deals with the study, the design and the development of algorithms that give computers the capability to learn without being **explicitly** programmed.
  ]
  
  .tr[
    â€” Arthur Samuel, 1959
  ]
]

&lt;img src="img/samuel.png" width="70%" style="display: block; margin: auto;" /&gt;




---
# .orange[What is **Machine Learning**]
  
.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    A computer program is said to learn from **experience** (E) with respect to some class of **tasks** (T) and performance measure  (P), if its **performance** at the given task improves with **experience**
  ]
  
  .tr[
    â€” _Machine Learning_ - Mitchell, 1997
  ]
]

.pull-left[

&lt;img src="img/Tom-Mitchell-2.webp" width="100%" style="display: block; margin: auto;" /&gt;
]
.pull-right[

&lt;br&gt;

**.orange[Learning]**: performance on **T** as measured by **P** improves with **E**.

&lt;br&gt;
&lt;small&gt;
  
E.g., Misclassification error (**P**) for diagnoses' classification (**T**) improves (i.e., become lower) after training on additional data (**E**).

E.g., Misclassification error (**P**) for diagnoses' classification (**T**) improves (i.e., become lower) after additional iterations of the training procedure (**E**) on the same data-set.
&lt;/small&gt;
]

---
# .orange[What is **Machine Learning**]
  

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    A task (red box) requires an appropriate mapping - a model- from data described by feature to outputs. **Obtaining** such mapping from training data is what constitute a **learning problem** (blue box).
  ]
  
  .tr[
    â€” _Machine Learning_ - Peter Flach, 2012
  ]
]



.left-column[
&lt;img src="img/PeterCartoon-square.jpg" width="100%" style="display: block; margin: auto;" /&gt;
]
.right-column[
&lt;img src="img/flach_learning_problem.png" width="100%" /&gt;
]



---
# .orange[Task]
  
A __task__ is something the ML must carry out

- the process of learning itself is not the task

- _Learning_ is .orange[the act of generate models] having the ability to perform the task



&lt;br&gt;
&lt;br&gt;


A __task__ is defined in terms of _how the ML should process a collection of Examples_, i.e. a .orange[dataset].


---
# .orange[Learning: are cars "learning"?!]

&lt;iframe width="800" height="450" src="https://www.youtube.com/embed/Aut32pR5PQA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

... or is the generative models which learns to produce well trained cars!?

---
# .orange[Task: Example]
  
  
&lt;small&gt;

**Learning Problem** | Task **T**  
---------------------|------------
Learning Checkers    | **Playing checkers**
Handwriting recognition | **Recognizing/Classifying handwritten words/numbers within images**
Self-driving car | **Driving from A to B**
Diseases extraction from EHR | **classify EHR by the disease reported (in free-text natural language)** 
Describe patient movement in bed | **At any given time provide position and dynamics of patients**

&lt;/small&gt;



---
# .orange[Performance]
  
A __performance__ is a quantitative measure for assessing the ability of ML

- performance is measured on the task being carried out

Usually __performance__ is measured in terms of:
  
- .orange[_accuracy_]: proportion of examples for which the model produces the correct output.

- .orange[_error rate_]: proportion of examples for which the model produces the incorrect output.

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
  

#### .orange[**WARNING**: unbalanced data require balanced metrics!]
  
  
  
---
# .orange[Performance: Example]
  
&lt;small&gt;

**Learning Problem** | Task **T** | Performance **P** 
---------------------|------------|-------------------
Learning Checkers    | Playing checkers | **% games won **
Handwriting recognition | Recognizing/Classifying handwritten words/numbers within images | **% correctly classified words **
Self-driving car | Driving from A to B | **Average distance traveled before an error (as judged by humans)**
Diseases extraction from EHR | classify EHR by the disease reported (in free-text natural language) | **% of EHR correctly classified**
Describe patient movement in bed | At any given time provide position and dynamics of patients | **% average error in position or dynamics**

&lt;/small&gt;

---
#.orange[Experience]
  
.orange[__Experience__] is primarily determined by the amount of supervision during the learning process and the availability of labeled data


---
#.orange[Experience: Example]
  
&lt;small&gt;

**Learning Problem** | Task **T** | Performance **P** | Experience **E** 
---------------------|------------|-------------------|-----------------
Learning Checkers    | Playing checkers | % games won | **playing (against itself)**
Handwriting recognition | Recognizing/Classifying handwritten words/numbers within images | % correctly classified words | **process data sets of handwritten words with given classification**
Self-driving car | Driving from A to B | Average distance traveled before an error (as judged by humans) | **Sequence of videos, still images, and steering commands recorded while observing a human driver**
Diseases extraction from EHR | classify EHR by the disease reported (in free-text natural language) | % of EHR correctly classified | **process EHRs with given classification**
Describe patient movement in bed | At any given time provide position and dynamics of patients | % average error in position or dynamics | **time-series of patient kinetic measures taken from wearable devices and bed weight sensors, and position and dynamics collected by videos recorded observing inbed patients**

&lt;/small&gt;




---
# .orange[How do Machines **learn**?]
  
Machine learning is concerned with finding functions that **_best_ predict** outputs (responses), given data inputs (predictors)

`$$Y \simeq f(X)$$` 
  




&lt;img src="img/ml-process.png" width="60%" style="display: block; margin: auto;" /&gt;

.orange[_Learners_] are algorithms that improve their skills (in producing better models/functions) by learning from old/known .orange[__(training)__] data.

&lt;br&gt;
&lt;br&gt;

&gt; A .orange[_learner_] uses data and experience to perform better over time (i.e., producing new models that performs better than the previous ones)



---
# .orange[How do Machines **learn**?]
  
  
  
.left-code[
In traditional programming:
- **provide** an algorithm (a finite set of instructions)
- **provide** .orange[input] data (no training/new distinction)
- **obtain** the desired result.


In machine learning:
- **provide** the .orange[training] input (data)
- **provide** the .orange[training] known/desired result
- **obtain** the .orange[learning algorithm] (ingesting _new_ data and returning _new_ outputs).

Machine Learning problems are .orange[*optimisation*] ones.

]

.right-plot[
  
&lt;img src="img/MLvsTrad.png" width="100%" style="display: block; margin: auto;" /&gt;
]













---
# Types of .orange[learning]

#### .orange[Unsupervised] learning

&gt; The input data is _not labeled_ (there are not right answers!)

Data is given to the model, which is left to learn optimal .orange[patterns]/.orange[clusters].



#### (Passive) .orange[Supervised] learning

&gt; The learning algorithm is provided with a set of inputs along with the corresponding .orange[correct] outputs.

The algorithm compares its current inferred output with the correct one to learn from its .orange[errors] (i.e., to minimize it).


#### .orange[Active] learning

&gt; The learning algorithm .orange[interactively] queries a user (the _oracle_) to label new data with the desired (correct) outputs.

With input data labeled on the fly by .orange[oracle's knowledge], the model cycles query/train stages on the left unlabeled data.



---
# .orange[Basic **components**]

.orange[**Training** dataset]: data used as input to the learner to train the model

.orange[**Validation** dataset]: data used by the learner for validation and optimization

.orange[Training model]: the ML artifact that comes out of the training process

.orange[Cost (or loss) function]: a function to optimize in the ML system (sum of squared errors over the training data set)

.orange[**Test** dataset]: data provided to the trained model for performance estimations






---
class: middle, hide-count, inverse

# .center[.orange[Break]]

(Unordered) tips: 
- get up
- stretch
- look _far away_ (relax your eyes)
- hydrate
- go to the bathroom

<div class="countdown" id="timer_b056e0b2" data-warn-when="1" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:5%;left:65%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>












---
class: inverse, middle, center, hide-count
# .orange[Classifiers]





---
class: middle center hide-count

&lt;img src="img/food.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---
# .orange[Classification]

Does data belong to class A? .orange[_**is this really a heart failure patient?**_]

&lt;br&gt;

Classifiers are the most commonly used ML algorithms in analytics applications


  -  Suggest possible patient diagnoses

  - Identify patients with high readmission risk

  - Automatically alert care providers early in the development of sepsis

  - Define the threshods for _abnormal_ lab results

  - Automatically differentiate between clinical and administrative documents

  - Recommend the most effective wellness or disease management intervention for a patient

  -  many, many more...



---
# .orange[Classification]
  
.left-code[
__Feature space__

- data: points in `\(\mathbb{R}^d\)`

- dimensions:  scalar measurements

&lt;br&gt;

__Classifier functions (_classifiers_)__

- a classifier for `\(K\)` classes is a function

$$
f:\mathbb{R}^d \to \{1, \ldots, K \}   
$$
- classifiers carve up the space into regions
]

.right-plot[
  
&lt;img src="img/classification_3.png" width="100%" style="display: block; margin: auto;" /&gt;
  
]




---
# .orange[Quantifying errors]

If `\(f\)` is our classifiers, i.e. for any given `\(x\)` we have `\(f(x) = \tilde{y}\)` is the predicted class (with `\(y\)` the real one), then

**Loss function** (for .orange[K] classes `\(\{1, \cdots, K\}\)`):

`$$\begin{split}\mathfrak{L}: \{1, \cdots, K\}&amp;\times \{1, \cdots, K\} &amp;\to [0, \infty)\\ (f(x)&amp;,\ y) &amp;\mapsto \mathfrak{L} (f(x),\ y)\end{split}$$`

&lt;br&gt;

&gt; If all mistakes are equally bad:
`$$\mathfrak{L}(i, j) = \begin{cases}
1 &amp; \textrm {if } i\neq j  \\
0 &amp; \textrm {if } i = j  \\
\end{cases}$$`

Note: if the outcome of `\(f\)` is a set of probabilities for the classes, the same definition is valid considering 
`$$\mathfrak{L}: \{p_1, \cdots, p_K\} \times \{1, \cdots, K\} \to [0, \infty)$$`


---
# .orange[Risk of classifier]
    
If the distribution of the classes is known, the .orange[risk] of classifier is the expected loss

$$
{\rm risk}(f) = \mathbb{E}[\mathfrak{L}(f(X), {\rm true\ class\ of\ } X)]
$$


We can evaluate the classifier by how large its risk is

&lt;br&gt;

&gt; The best way to possibly train a classifier is by **minimizing its risk**

&lt;br&gt;
&lt;br&gt;


&gt; N.B. The above one is a sort of common **_misuse of notation_**: a classifier is **.orange[a (single!) model]**, and **cannot be trained**!! when we say "train a model" the real meaning is 
.center[**"a MLT start producing models, somehow; new ones replacing the prevouses"**.]
Interpreting "replacement" like "modification", we can pretend that a (**.orange[single]**...) model is trained.
  


---
class: inverse, middle, center, hide-count
# .orange[Classifiers]

Main MLT examples

  
---
# .orange[Nearest neighbor]
  
.orange[__Idea:__] use training data itself as classifier

- Given: data point `\(x\)`
  
  - Find training data point closest to `\(x\)`
  
  - Assign `\(x\)` the label of closest point


---
#.orange[Nearest neighbor]

&lt;img src="img/knn.png" width="60%" style="display: block; margin: auto;" /&gt;

---
##.orange[Nearest neighbor (100 data points)]

&lt;img src="img/knn_2.png" width="60%" style="display: block; margin: auto;" /&gt;


---
class: inverse, middle, center, hide-count

# Your turn

.left[
How can we __train__ a model using a nearest neighbor MLT?

(i.e. what can be the _experience_?)
]

<div class="countdown" id="timer_8a0f5d01" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:20%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---
# .orange[k-Nearest] Neighbor (kNN)

- Find `\(k\)` closest training points

- Take a majority vote between these points


&gt; .orange[__Rule of thumb:__] 3NN often works surprisingly well


---
##.orange[k-Nearest neighbor]

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/knn_k.png" alt="https://medium.com/analytics-vidhya/diabetes-classification-with-knn-and-logistic-regression-2edd3760a8c7" width="60%" /&gt;
&lt;p class="caption"&gt;https://medium.com/analytics-vidhya/diabetes-classification-with-knn-and-logistic-regression-2edd3760a8c7&lt;/p&gt;
&lt;/div&gt;


---
class: inverse, middle, center, hide-count

# Your turn

.left[
How can we __train__ a model using a k-nearest neighbor MLT?

(i.e. what can be the _experience_?)
]

<div class="countdown" id="timer_696c44a3" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:20%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, middle, center, hide-count

# Your turn

.left[
**Increasing** k, we provide **.orange[more or less] flexibility** to the model?

Which are the **minimum** and **maximum** possible k?
]

<div class="countdown" id="timer_bef92446" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:20%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>



---
#.orange[kNN: drawbacks]

In large dataset, finding nearest data points is expensive

Computational burden grows with dimension

&gt; it is the method of choice when dataset is small

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

__What to do for large dataset:__

- Extract a concise summary



---
# .orange[Linear classifiers] 

&lt;img src="img/linear_classifier_3.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Linear classifiers] 

&lt;img src="img/linear_classifier_5.png" width="70%" style="display: block; margin: auto;" /&gt;

.center[draw the convex hull]




---
#.orange[Linear classifiers:&lt;br&gt;Maximum margin hyperplane] 


&lt;img src="img/linear_classifier_6.png" width="70%" style="display: block; margin: auto;" /&gt;
  

.footnote[An hyperplane is a **subspace of co-dimension = 1** of a space (i.e. 1 dimension less then the space ones).

E.g., a line (1D) in a plane (2D); a plane (2D) in a 3D space; a 23D subspace in a 24D space.]

---
#.orange[Linear classifiers:&lt;br&gt;Maximum margin hyperplane]

&lt;br&gt;

&lt;img src="img/linear_classifier_7.png" width="70%" style="display: block; margin: auto;" /&gt;


---
#.orange[Linear classifiers: Support-Vector Machine] 


A maximum margin classifier is called __Support-Vector Machine__

Training a SVM is a .orange[convex] optimization problem

&gt; Empirically, SVM are among the most powerful (and fast) classifiers




---
# .orange[Limitations of linear classifiers]

.pull-left[
  
Problem 1: **curved optimal decision boundary**
  
  - SVM solves Problem 1 using the so-called .orange[_kernel trick_]

&lt;br&gt;
&lt;br&gt;
  
Problem 2: **classes may overlap**
  
- SVM solve Problem 2 by:
  
  - permitting .orange[misclassified] training points (**C** hyper-parameter)

  - each such point contributes a .orange[_cost_] to the optimization target function

  - using the .orange[kernel tricks]
  
]

.pull-right[
&lt;img src="img/classification_3.png" width="100%" style="display: block; margin: auto;" /&gt;
]




---
# .orange[Example of the kernel trick]

Suppose you have .orange[non-linearly separable] data



&lt;img src="img/kernel_1.png" width="70%" style="display: block; margin: auto;" /&gt;

&gt; Accuracy of classification given by the linear classifier: .orange[75%]




---
# .orange[Example of the kernel trick]

Project it into a three-dimensional space where the new coordinates are 

.left-column[
`$$\begin{cases}
X_1 &amp;= y_1^2 \\
X_2 &amp;= y_2^2 \\
X_3 &amp;= \sqrt{2}y_1y_2
\end{cases}$$`
]

.right-column[
&lt;img src="img/kernel.gif" width="90%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Example of the kernel trick]

Run the SVM on the trasformed data 

.right-column[
&lt;img src="img/kernel_2.gif" width="90%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Example of the kernel trick]

Now you got completely _linearly_ separable data


&lt;img src="img/kernel_2.png" width="70%" style="display: block; margin: auto;" /&gt;

&gt; Accuracy of classification given by the SVM classifier: .orange[100%]




---
#.orange[Limitations of linear classifiers]

Problem 3: more than two classes 

- Can be addressed by combining multiple linear classifier

&lt;br&gt; 
&lt;br&gt; 

&gt; Some classifiers naturally apply to more classes, e.g., kNN.



---
class: inverse, middle, center, hide-count

# Your turn

.left[
The **C** parameter of SVMs MLTs determines the amount of violation admitted, i.e. how much **.orange[weight]** have data _crossing the line_ (so, it cannot be negative).

C = 0 is "violation is not relevant" (i.e., you can cross the line as much as you want).

**Increasing** C, we provide **.orange[more or less] flexibility** to the model?
]

<div class="countdown" id="timer_6f2626f2" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:15%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>





---
# .orange[Ensemble classifiers]


__Weak classifier__

Consider two classes of equal size: assign class by coin flip: 50% expected error

&gt; weak classifier: .orange[error rate **slightly below** 50%]


__Ensemble Classifier__
- trains .orange[many _weak_] classifiers

- .orange[combines results] by majority vote

If weak classifiers are applicable to `\(k&gt;2\)` classes, so it is ensemble.



&lt;br&gt;&lt;br&gt;&lt;br&gt;

**Important examples: .orange[Random Forests]**




---
# .orange[Classification by majority vote]

`\(m\)` classifiers take a vote 

&gt; let us suppose `\(m\)` is an odd number

Two choices:
- correct = `\(1\)`
- wrong = `\(-1\)`

Decision is made by simple majority

- for two classes and classifiers `\(f_1,\ldots ,f_m\)` with output `\(\pm1\)`
majority vote at input `\(x\)` is
`$$\rm sgn \left( \sum_{j=1}^m f_j(x)\right)$$`





---
# .orange[Classification by majority vote]

Does the majority make the right choice?

.pull-left[
  Let's assume

-  each classifier makes the right choice with probability `\(p\in [0,1]\)`

- votes stochastilly independent when regarded as random outcomes
]


.pull-right[
.panelset[
&lt;img src="index_files/figure-html/unnamed-chunk-31-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]
]
]




---
## .orange[Classification by majority vote]

&lt;img src="index_files/figure-html/unnamed-chunk-32-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[_Weak_ learner: tree classifier]


&lt;img src="img/tree_1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[_Weak_ learner: tree classifier]

&lt;img src="img/tree_2.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[_Weak_ learner: tree classifier]

&lt;img src="img/tree_3.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[_Weak_ learner: tree classifier]

&lt;img src="img/tree_4.png" width="70%" style="display: block; margin: auto;" /&gt;

---
# .orange[_Weak_ learner: tree classifier]


.pull-left[
&lt;img src="img/tree_4.png" width="100%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/tree_5.png" width="100%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Random forest]
  
.orange[Tree training]: Input `\(n\)` training points of classes `\(1,\ldots, K\)`
  
- select `\(n\)` points uniformly at random with replacement

- train a tree on the randomized data set


.orange[For each tree]:
  
- in each step, select `\(m\)` axes at random (**mtry** hyper-parameter)

- compute best split point for each of these axes

- split along the one that minimizes error


&gt; .orange[Train **ntree** trees in total]
&gt;  - compute class label of new point `\(x\)` under each of the **ntree** trees
&gt;  - take majority vote




---
#.orange[Hyperplane comparison]


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/hyperplane.png" alt="2 classes classification" width="70%" /&gt;
&lt;p class="caption"&gt;2 classes classification&lt;/p&gt;
&lt;/div&gt;

---
#.orange[Hyperplane comparison]

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/hyperplane_2.png" alt="Hyperplane for XOR pattern" width="65%" /&gt;
&lt;p class="caption"&gt;Hyperplane for XOR pattern&lt;/p&gt;
&lt;/div&gt;





---
class: inverse, middle, center, hide-count

# Your turn

.left[
The **mtry** parameter of RF MLTs determines how many variables are randomly selected to train each tree.

- **Increasing** mtry, we provide **.orange[more or less] flexibility** to the model?
- Which are the **minimum** and **maximum** possible mtry?

The **ntree** parameter of RF MLTs determines how many trees there are in the forest (i.e., you are going to train).

- What is the effect of **increasing** ntree?

]

<div class="countdown" id="timer_63873132" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:15%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>




---
class: middle, hide-count, inverse

# .center[.orange[Break]]

(Unordered) tips: 
- get up
- stretch
- look _far away_ (relax your eyes)
- hydrate
- go to the bathroom

<div class="countdown" id="timer_8a60f592" data-warn-when="1" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:5%;left:65%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>














---
class: inverse, middle, center, hide-count
# .orange[Model selection]



---
# .orange[Overfitting]
  
  
Sample data acts as proxy for underlying data source

.orange[_Over-fitting_] means adapting too closely to the idiosyncrasies of a sample set

**Result**: Small error on training data but .orange[poor predictive performance]!
  
&lt;img src="img/overfit.jpg" width="90%" style="display: block; margin: auto;" /&gt;


---
# .orange[Overfitting]
  
Model is .orange[not able to generalize]

Learn the data and .orange[not the underlying function]

Performs well on training data but .orange[poorly with new data]


&lt;img src="img/figure3.png" width="100%" style="display: block; margin: auto;" /&gt;


---
# .orange[Overfitting: example]

Two alternative models of human papillomavirus infection and its progression to cervical cancer (CIN) 

The complex model includes multiple stages of pre-cancerous lesions which can progress or regress at different rates (model parameters) 

&lt;br&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/Figure_8.png" alt="Basu 2013" width="100%" /&gt;
&lt;p class="caption"&gt;Basu 2013&lt;/p&gt;
&lt;/div&gt;


---
# .orange[Overfitting ]

Prevalence data of (CIN) generated using more complex model over a 30-year period among a fictional cohort of young women

The complex model (in green) actually has a better .orange[_fit_] to the early prevalence data (solid red dots) than does the simpler model (in blue)...

However, the complex model produced a pattern that poorly forecasts future prevalence (hollow red dots)


&lt;img src="img/Figure_9.png" width="60%" style="display: block; margin: auto;" /&gt;


---
# .orange[Overfitting]

**.orange[Every]** additional parameter in the model introduces **new sources of uncertainty** and potential to affect results in non-intuitive ways that may either be useful or deceptive

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

&gt; Complex models must be well-characterized in terms of their behavior before they are used for .orange[__forecasting__ ]



---
name: berra
class: center, middle, hide-count

&lt;img src="img/yogi-berra-photo-quote-1.jpg" width="100%" style="display: block; margin: auto;" /&gt;





---
# .orange[Bias and Variance trade-off]
  
In order to minimize test error on new data points we need to
&gt; **select a function** that achieves **.orange[_low variance_]** and **.orange[_low bias_]**.


- .orange[**Variance**] refers to the amount by which our predictions would **change if we estimated using a different training set**. 
&gt; The more flexible the model, the higher the variance.

- .orange[**Bias**] refers to the **error that introduced by the approximation** we are making with our model (represent complicated data by a simple model). 
&gt; The more simple the model, the higher the bias.

There is a .orange[trade off] between increasing variance (flexibility) and decreasing bias (simplicity) and vice versa.

&lt;img src="img/tradeoff.png" width="30%" style="display: block; margin: auto;" /&gt;


---
#.orange[Bias variance trade-off]
  
  
A predictor having high bias or variance won't do well in predicting on new data

&lt;img src="img/BV.png" width="70%" style="display: block; margin: auto;" /&gt;


Good, generalizable predictors need to have .orange[both low bias and low variance]




---

#.orange[(Hyper-)parameters]

 
MLT                 |parameters             | Hyper-parameters|
--------------------|-----------------------|-----------------
Decision tree       | Splits' locations     | # splits
Random forest       | Splits' locations     | # splits&lt;br&gt;# trees&lt;br&gt;# dimension (randomly selected)
SVM                 | Hyper-plane's position | type of nonlinearity&lt;br&gt;margin&lt;br&gt;overlap
Logistic regression | `\(\beta\)`s              | polynomial degrees&lt;br&gt;# nodes for splines&lt;br&gt;interactions
ANN/DL              | weights               | # layers&lt;br&gt;# neurons/layer&lt;br&gt;# training's epochs&lt;br&gt;batch size&lt;br&gt;learning rate
  


---
#.orange[Cross-validation]

&gt; How to select an adequate model based on sample data?

&lt;br&gt;

__Recall__: model selection **.orange[chooses a model complexity]** (hyper-parameter)
  
  - Training a classifiers chooses parameter values
  
  - The training can often be formulated as minimizing the training error

&lt;br&gt;
&lt;br&gt;

.orange[Model selection **cannot be performed by minimizing the training error**]

  - it would lead to overfitting

---
# .orange[Cross-validation]

1. Split data into three sets

  a. training set
  
  b. validation set
  
  c. test set (hold out set)


2. Train classifiers with **.orange[different hyper-parameters]** on training set

3. Select that with smallest **.orange[prediction error on validation set]**

4. Estimate **.orange[performance on test set]**

&lt;br&gt;

**.orange[Separate test set is **crucial**]**:

  - prediction error estimate on validation set is confounded by model selection



---
# .orange[Cross-validation]

Data splitting estimates the .orange[prediction error from data]

&lt;br&gt;

Prediction error estimates can be used in two ways

  - model selection `\(\Leftrightarrow\)` .orange[optimize] performance

  - classifier assessment `\(\Leftrightarrow\)` .orange[interpret] performance (estimates the prediction error of the final choice of classifier)


&lt;br&gt;
&lt;br&gt;


We **must not use** **.orange[same data for both]**







---
# .orange[Leave-one-out cross-validation]


For every data point `\(x_i,\ i = 1, \ldots, n\)`:

  - train the model on every point except the single point `\(X_i\)`,
  
  - compute the validation error on the held out point


&lt;br&gt;

Average the test error


---
class: hide-count
# .orange[Leave-one-out cross-validation]

&lt;img src="img/cv_1.png" width="90%" style="display: block; margin: auto;" /&gt;


---
class: hide-count
# .orange[Leave-one-out cross-validation]

&lt;img src="img/cv_2.png" width="90%" style="display: block; margin: auto;" /&gt;



---
#.orange[K-fold cross validation]


0. .orange[Remove test set] and set it aside

1. Divide remaining data into `\(K\)` .orange[equally sized] blocks

2. Cross-validate: for `\(k = 1,\cdots, K\)`

  - remove block `\(k\)` from training data
  
  - train classifier on remaining blocks.
  
  - estimate prediction error on block `\(k\)`
  
3. Estimates over all `\(k\)` and select best classifier

4. Retrain the best classifiers (i.e. with its hyper-parameters) on the whole training set (all K sets!)

5. When classifier is chosen and retrained, estimate its performance .orange[on test set]



---
# .orange[K-fold cross validation]

The misclassification error rate is computed on the observations in the held-out fold. 

&lt;img src="img/Cv1.png" width="100%" style="display: block; margin: auto;" /&gt;




---
# .orange[K-fold cross validation]

This procedure is .orange[repeated K] times; each time, a different group of observations is treated as a validation set.


&lt;img src="img/Cv2.png" width="90%" style="display: block; margin: auto;" /&gt;

---
# .orange[K-fold cross validation]

The .orange[CV error rate] is then calculated as the average of these K error rates.


&lt;img src="img/Cv3.png" width="90%" style="display: block; margin: auto;" /&gt;





---
# .orange[K-fold cross validation]
  
&lt;img src="img/splits.png" width="100%" style="display: block; margin: auto;" /&gt;

Generally, .orange[k between 5 and 10] avoids over-training the model (variance), whilst avoiding too few training points (bias)


---
#.orange[Cross validation variability]
  
  
  
&lt;img src="img/overfitting.png" width="100%" style="display: block; margin: auto;" /&gt;






---
class: inverse, middle, center, hide-count

# Your turn

.left[

- What is the effect of **Increasing** k in a k-fold cross-validation procedure?
- Which are the **minimum** and **maximum** possible k?

]

<div class="countdown" id="timer_d4919dad" data-warn-when="10" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:15%;left:70%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>





---
class: inverse, middle, center, hide-count

# Ready to go _deeper_?

&lt;img src="img/perplesso.jpg" width="100%" style="display: block; margin: auto;" /&gt;



---
class: middle, hide-count, inverse

# .center[.orange[Break]]

(Unordered) tips: 
- get up
- stretch
- look _far away_ (relax your eyes)
- hydrate
- go to the bathroom

<div class="countdown" id="timer_dff523dd" data-warn-when="5" data-update-every="1" data-play-sound="true" tabindex="0" style="bottom:5%;left:65%;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">60</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>










---
class: inverse, middle, center, hide-count

# Deep Learning

---
# Neuron

I.e., anything more than old new-fashioned (generalized*) logistic regressions

&lt;br&gt;

&lt;img src="img/neuron.gif" width="60%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

\*generalized := activation/link is any **non-linear**, **differentiable**, `\(\mathbb{R}^n\to \mathbb{R}\)` function.




---
# Fully connected network 

&lt;img src="img/mlp.png" width="40%"/&gt;&lt;img src="img/fc.png" width="25%"/&gt;&lt;img src="img/descent.gif" width="30%"/&gt;

&lt;br&gt;

&lt;img src="img/loss.png" width="100%"/&gt;



---
### Can we try to write it down?
3 input; 2 hidden layer w/ 2 neurons each; 1 (sigmoid) output 




---
class: inverse, middle, center, hide-count

# Unstructured data

.left[
- Multi-dimensional single-information (e.g., images)
- Sequential one-dimension privileged single-information (e.g., text/signals)
]


---
## Multi-dimensional single-information

### Convolutional networks

&lt;img src="img/convExample.png" width="100%" style="display: block; margin: auto;" /&gt;


---
# Convolutional networks


&lt;img src="img/conv.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---
# Convolutional networks


&lt;img src="img/multi-cnn.png" width="100%" style="display: block; margin: auto;" /&gt;





---
# Convolutional networks

&lt;br&gt;&lt;br&gt;

&lt;img src="img/cnn-struct.png" width="100%" style="display: block; margin: auto;" /&gt;


---
### One-dimension privileged single-information

#### Sequencies (input/output)

&lt;br&gt;
  
&lt;img src="img/sequences.png" width="100%" style="display: block; margin: auto;" /&gt;



---
# Recurrent networks
  
  
&lt;img src="img/rnn-full_CL.png" width="100%" style="display: block; margin: auto;" /&gt;


&lt;small&gt;
  
.pull-left[
  `\(x^{&lt;t&gt;}\)`: input position t 
  
  `\(T_x\)`: length of input
  
  `\(W^{[l]}_{yx}\)` :weight matrix used with input x for output y on layer l
  
  `\(b^{[l]}_y\)`: (bias) vector for output y on layer l
]

.pull-right[
  `\(y^{&lt;t&gt;}\)` : output position t 
  
  `\(T_y\)`: length of output
  
  `\(a^{[l]}_{&lt;t&gt;}\)` : activation vector at position t on layer l
]

&lt;/small&gt;


---
# Take them all
  
&lt;small&gt;&lt;small&gt;
  
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/multi-dl.jpg" alt="&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;Network from https://www.sciencedirect.com/science/article/pii/S0007091219306361 &amp;lt;br&amp;gt;Bradley A. Fritz, et al. 'Deep-learning model for predicting 30-day postoperative mortality' - BJA 2019" width="100%" /&gt;
&lt;p class="caption"&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;Network from https://www.sciencedirect.com/science/article/pii/S0007091219306361 &lt;br&gt;Bradley A. Fritz, et al. 'Deep-learning model for predicting 30-day postoperative mortality' - BJA 2019&lt;/p&gt;
&lt;/div&gt;
&lt;/small&gt;&lt;/small&gt;
















---
class: inverse, middle, center, hide-count
# .orange[A Machine Learning usecase project&lt;br&gt;in healthcare]




---
class: inverse, center, middle, hide-count
# **Case Study:&lt;br&gt;&lt;br&gt;.orange[Expanding] PubMed .orange[searches] &lt;br&gt;.orange[to] ClinicalTrials.gov**


---
# SRs on .orange[Clinical Trials]

Clinical trial registries are under-utilized:

- No hierarchical branching structure
- Text search is based on few fields
- Cannot use queriesâ€™ combination
.right[Jones et al 2014, https://doi.org/10.1186/2046-4053-3-126]


&lt;br&gt;

.orange[Baudart et al] 2017 (https://doi.org/10.1136/bmj.j448) reanalyzed 14 Systematic reviews and Meta-analyses*, searching not only through standard databases but also in clinical trial registries:

- Increase of patients .orange[from 10% to 50%]
- Change in statistics .orange[up to 29%]

&gt; **~[1.5, 2] years of work for two researchers**:
&gt;
&gt;  - from: 2015/03/16 (first search)
&gt;  - to: [2016/08/11 (first submission), 2017/01/17 (last revision)]


&lt;small&gt;* All the (RCTs) assessing pharmaceutical treatments published between June 2014 and January 2015 that did not report a trial registry search.


---
### Method

**Learning**: .orange[Passive Supervised]  --  **Task**: Classification (.orange[many-to-one])


**Training set**: PubMed (294 positives and 7,200 negative records overall)

**Test**: ClinicalTrials.gov (233,609 records, 2017/01/05 snapshot)

### Results

**Model left out 1 of 133 human-detected** positive citations .orange[from 233,609 trials] in ClinicalTrials.gov


Total number of records from our automated search (**predicted positives**) was .orange[lower than] the number of records from .orange[the manual search] in half the cases (with a mean of 472 and a maximum of 2119 records compared with 572 and 2680, respectively, retrieved by Baudard et al).


The ability to **distinguish on-topic** from off-topic articles ranged from an area under the receiver operator characteristic curve .orange[(AUC-ROC) of 93.4% to 99.9%].


&lt;small&gt;.right[
â€” Lanera C. et al 2018&lt;br&gt; https://doi.org/10.1016/j.jclinepi.2018.06.015
]


---
#### **Flowchart**

&lt;img src="img/costumer.jpg" width="100%"&gt;














---
class: inverse, middle, center, hide-count
# .orange[Best practices for implementing&lt;br&gt;Machine Learning]






---
## .orange[Start quickly and simple; **next iterate**!]

Keep .orange[robustness]
- less model complexity and fewer parameters are always beneficial 


Keep it .orange[simple] both for model selection and data for your analysis
- start with the minimal set of data that could get you to a good result



## .orange[Treat data with suspicious]
  
.orange[Look] at the data 
- dig into its details 
- look for correlations
- systematic biases, errors, and flaw

.orange[Normalize] input data 
- ML algorithms can perform .orange[poorly and slowly] if there are large differences in scale between different features



---
## Validate (and fine-tune) your Model
Separate your data into .orange[training], .orange[validation], and .orange[test sets].

&gt; .orange[If you take **ANY** decision after having seen a performance on a data set, it becomes a training one (even if you have treated it as a test)]

## Do not be fooled by Accuracy

For event that only happens 1% of the time,  you can easily report an accuracy of 99%: meaningless.

Before starting a (classification) project, better figure out which precision and recall application (or _metrics_) requires to be useful

&gt; - .orange[Build the model with these metrics on your mind]
&gt; - .orange[When in doubt use balanced metrics]






---
## .orange[Healthcare does not trust black boxes]
  
Some ML methods are more transparent than others    

- Clustering, tend to be easy to interpret, because they create groupings of concepts      

- Linear regression can tell how important each feature is to the final output 

- Same for decision trees, but they are easily prone to overfitting! 


&lt;br&gt;
  
Random forests are .orange[difficult to interpret].

Neural networks and deep learning are .orange[truly black boxes], i.e., very little transparency to what is important in the decision making process (or very high effort to obtain it).















---
class: inverse, center, middle, hide-count


&lt;img src="img/procione.jpeg" width="50%" /&gt;


&lt;br&gt;
# Thank .orange[you] for the attention!


&lt;br&gt;

Slides: https://CorradoLanera.github.io/ws-mlt


[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg>](https://www.unipd-ubep.it/) [**www.unipd-ubep.it**](https://www.unipd-ubep.it/) | 
[<svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M128 0C110.3 0 96 14.3 96 32V224h96V192c0-35.3 28.7-64 64-64H480V32c0-17.7-14.3-32-32-32H128zM256 160c-17.7 0-32 14.3-32 32v32h96c35.3 0 64 28.7 64 64V416H576c17.7 0 32-14.3 32-32V192c0-17.7-14.3-32-32-32H256zm240 64h32c8.8 0 16 7.2 16 16v32c0 8.8-7.2 16-16 16H496c-8.8 0-16-7.2-16-16V240c0-8.8 7.2-16 16-16zM64 256c-17.7 0-32 14.3-32 32v13L187.1 415.9c1.4 1 3.1 1.6 4.9 1.6s3.5-.6 4.9-1.6L352 301V288c0-17.7-14.3-32-32-32H64zm288 84.8L216 441.6c-6.9 5.1-15.3 7.9-24 7.9s-17-2.8-24-7.9L32 340.8V480c0 17.7 14.3 32 32 32H320c17.7 0 32-14.3 32-32V340.8z"/></svg>](mailto:Corrado.Lanera@ubep.unipd.it) [**Corrado.Lanera@ubep.unipd.it**](mailto:Corrado.Lanera@ubep.unipd.it)

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>](https://twitter.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>](https://telegram.me/CorradoLanera)
**@CorradoLanera** | 
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/UBESP-DCTV)
**@UBESP-DCTV**

[<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M128 0c13.3 0 24 10.7 24 24V64H296V24c0-13.3 10.7-24 24-24s24 10.7 24 24V64h40c35.3 0 64 28.7 64 64v16 48V448c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64V192 144 128C0 92.7 28.7 64 64 64h40V24c0-13.3 10.7-24 24-24zM400 192H48V448c0 8.8 7.2 16 16 16H384c8.8 0 16-7.2 16-16V192zM329 297L217 409c-9.4 9.4-24.6 9.4-33.9 0l-64-64c-9.4-9.4-9.4-24.6 0-33.9s24.6-9.4 33.9 0l47 47 95-95c9.4-9.4 24.6-9.4 33.9 0s9.4 24.6 0 33.9z"/></svg>](https://calendly.com/corradolanera) [**calendly.com/corradolanera**](https://calendly.com/corradolanera)


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
