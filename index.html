<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Artificial Intelligence and Machine Learning in Supporting Clinical Decision</title>
    <meta charset="utf-8" />
    <meta name="author" content="CorradoLanera" />
    <script src="index_files/header-attrs-2.14/header-attrs.js"></script>
    <link href="index_files/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <script src="index_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="index_files/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="index_files/shareon-1.4.1/shareon.min.js"></script>
    <link href="index_files/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link href="index_files/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="index_files/panelset-0.2.6/panelset.js"></script>
    <link href="index_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"x73aa38964b5456e8d405c244824ee72","expires":1}</script>
    <script src="index_files/himalaya-1.1.0/himalaya.js"></script>
    <script src="index_files/js-cookie-3.0.0/js.cookie.js"></script>
    <link href="index_files/editable-0.2.6/editable.css" rel="stylesheet" />
    <script src="index_files/editable-0.2.6/editable.js"></script>
    <script src="index_files/freezeframe-5.0.2/freezeframe.min.js"></script>
    <script src="index_files/xaringanExtra-freezeframe-0.0.1/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <script src="index_files/fabric-4.3.1/fabric.min.js"></script>
    <link href="index_files/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="index_files/xaringanExtra-extra-styles-0.2.6/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
    <meta name="description" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="generator" content="xaringan and remark.js"/>
    <meta name="github-repo" content="CorradoLanera/ws-mlt"/>
    <meta name="twitter:title" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="twitter:description" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta name="twitter:url" content="https://CorradoLanera.github.io/ws-mlt/#1"/>
    <meta name="twitter:image" content="https://github.com/CorradoLanera/ws-mlt/raw/main/img/cover.jpg"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:creator" content="@CorradoLanera"/>
    <meta name="twitter:site" content="@CorradoLanera"/>
    <meta property="og:title" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta property="og:description" content="Artificial Intelligence and Machine Learning in Supporting Clinical Decision"/>
    <meta property="og:url" content="https://CorradoLanera.github.io/ws-mlt/#1"/>
    <meta property="og:image" content="https://github.com/CorradoLanera/ws-mlt/raw/main/img/cover.jpg"/>
    <meta property="og:type" content="website"/>
    <meta property="og:locale" content="en_US"/>
    <meta property="article:author" content="UBEP"/>
    <link href="index_files/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="index_files/countdown-0.3.5/countdown.js"></script>
    <link href="index_files/font-awesome-animation-1.0/font-awesome-animation-emi.css" rel="stylesheet" />
    <script src="index_files/fontawesome-5.0.13/js/fontawesome-all.min.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle, bg_title, hide-count


&lt;img src="img/logo_800anni.png" width="150px"/&gt;
&lt;img src="img/DSCTV.png" width="50px"/&gt;
&lt;img src="img/UBEP.png" width="50px"/&gt;
&lt;img src="img/LAIMS.png" width="50px"/&gt;




<style>.xe__progress-bar__container {
  top:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #0051BA;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>

<style>.shareagain-bar {
--shareagain-foreground: rgb(255, 255, 255);
--shareagain-background: rgba(0, 0, 0, 0.5);
--shareagain-facebook: none;
--shareagain-pinterest: none;
--shareagain-reddit: none;
}</style>




&lt;style type="text/css"&gt;
.left-code {
  color: #777;
  width: 38%;
  height: 92%;
  float: left;
}
.right-code {
  color: #777;
  width: 55%;
  height: 92%;
  float: right;
  padding-top: 0.5em;
}
.left-plot {
  width: 43%;
  float: left;
}
.right-plot {
  width: 60%;
  float: right;
}
.hide-count .remark-slide-number {
  display: none;
}

.bg_title {
  position: relative;
  z-index: 1;
}

.bg_title::before {    
      content: "";
      background-image: url('img/bg1.png');
      background-size: contain;
      position: absolute;
      top: 0px;
      right: 0px;
      bottom: 0px;
      left: 0px;
      opacity: 0.3;
      z-index: -1;
}

&lt;/style&gt;





&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
# **.orange[How] Machine .orange[Learning]**&lt;br&gt;and **Artificial .orange[Intelligence]** can&lt;br&gt;**Support Clinical .orange[Decision]**

&lt;br&gt;
&lt;br&gt;

**Biostatistics Seminaries** - Padova, 2022/05/27 -

Ph.D. Course in Specialistic Traslational Medicine "G.B. Morgagni"

Corrado Lanera | [**Unit of Biostatistics, Epidemiology, and Public Health**](https://www.unipd-ubep.it/)



---
class: hide-count
.panelset[
.panel[.panel-name[Code]

```r
# The downloaded csv with graph data of your PubMed query
pmlt_path &lt;- here("data/PubMed_Timeline_Results_by_Year.csv")

pmlt_path |&gt; 
  read_csv(skip = 1L) |&gt;  # The first line is the query!
  ggplot(aes(x = Year, y = Count)) + 
  geom_point() +
  geom_label(
    aes(label = glue::glue("Total = {sum(Count)}")),
    x = 1980,
    y = 1e4
  ) +
  labs(
    title = "Historical progression of MLT/AI papers in \"our\" field",
# The first line is the query :-)
    caption = read_lines(pmlt_path, n_max = 1)
  ) +
  theme(plot.caption = element_text(size = 7))  # It's a long query...
```



]

.panel[.panel-name[Output]

&lt;img src="index_files/figure-html/unnamed-chunk-2-1.png" width="70%" /&gt;

]
]



---
class: inverse, hide-count
# What we are going to see

Purpose of this seminary is to introducing .orange[what is] Machine Learning, why/in what is different from other (statistical) tools, how to understand (and .orange[trust]!) it's results, and looking at .orange[some example] and .orange[best practice] in conducing a machine learning project.

My principal aim is to let you able to .orange[understand] (and .orange[evaluate] the quality!) of a machine learning project when used for clinical purposes.

Spoiler: I do not show you any (other) R code... hopefully.


---
class: hide-count
# .orange[Acknowledgement]

The following slides and their contents were produced thanks to the preciuos work of .orange[**Paola Berchialla**]

.center[
&lt;img src="img/thankyou-robot.jpg" width="50%" /&gt;
]

&lt;br&gt;&lt;br&gt;

&gt; Special thanks also to .orange[**Cristiana Vettori**] for having supported me in all the administratives related to this presentation.


---
class: inverse, bottom, right, hide-count


&lt;img src="img/profilo_CL.jpg" width="50%" /&gt;
# Find me at...


[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg>](https://www.unipd-ubep.it/) [**www.unipd-ubep.it**](https://www.unipd-ubep.it/)

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/UBESP-DCTV)
**@UBESP-DCTV**

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>](https://twitter.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z"/></svg>](https://telegram.me/CorradoLanera)
**@CorradoLanera**

[<svg aria-hidden="true" role="img" viewBox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M160 448c-25.6 0-51.2-22.4-64-32-64-44.8-83.2-60.8-96-70.4V480c0 17.67 14.33 32 32 32h256c17.67 0 32-14.33 32-32V345.6c-12.8 9.6-32 25.6-96 70.4-12.8 9.6-38.4 32-64 32zm128-192H32c-17.67 0-32 14.33-32 32v16c25.6 19.2 22.4 19.2 115.2 86.4 9.6 6.4 28.8 25.6 44.8 25.6s35.2-19.2 44.8-22.4c92.8-67.2 89.6-67.2 115.2-86.4V288c0-17.67-14.33-32-32-32zm256-96H224c-17.67 0-32 14.33-32 32v32h96c33.21 0 60.59 25.42 63.71 57.82l.29-.22V416h192c17.67 0 32-14.33 32-32V192c0-17.67-14.33-32-32-32zm-32 128h-64v-64h64v64zm-352-96c0-35.29 28.71-64 64-64h224V32c0-17.67-14.33-32-32-32H96C78.33 0 64 14.33 64 32v192h96v-32z"/></svg>](mailto:Corrado.Lanera@ubep.unipd.it) [**Corrado.Lanera**__.orange[@ubep.unipd.it]__](mailto:Corrado.Lanera@ubep.unipd.it)



---
class: inverse, middle
# .center[**.orange[Overview]**]

- .orange[**Overview**]: what does it means "Machine Learning"?

- .orange[**Classifiers**]

- Model .orange[**selection**] and .orange[**evaluation**]

- .orange[**Neural Networks**] and .orange[**Deep Learning**]

- A tour of Machine Learning .orange[**algorithms**] in healthcare

- .orange[**Best practices**] for implementing Machine Learning








---
class: inverse, middle, center, hide-count
# .orange[Overview]

What does it means "Machine Learning"?




---
# .orange[What is **Machine Learning**]
  

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    Machine Learning deals with the study, the design and the development of algorithms that give computers the capability to learn without being **explicitly** programmed.
  ]
  
  .tr[
    — Arthur Samuel, 1959
  ]
]

&lt;img src="img/samuel.png" width="70%" style="display: block; margin: auto;" /&gt;




---
# .orange[What is **Machine Learning**]
  
.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    A computer program is said to learn from **experience** (E) with respect to some class of **tasks** (T) and performance measure  (P), if its **performance** at the given task improves with **experience**
  ]
  
  .tr[
    — _Machine Learning_ - Mitchell, 1997
  ]
]

.pull-left[

&lt;img src="img/Tom-Mitchell-2.webp" width="100%" style="display: block; margin: auto;" /&gt;
]
.pull-right[

&lt;br&gt;

**.orange[Learning]**: performance on **T** as measured by **P** improves with **E**.

&lt;br&gt;
&lt;small&gt;
  
E.g., Misclassification error (**P**) for diagnoses' classification (**T**) improves (i.e., become lower) after training on additional data (**E**).

E.g., Misclassification error (**P**) for diagnoses' classification (**T**) improves (i.e., become lower) after additional iterations of the training procedure (**E**) on the same data-set.
&lt;/small&gt;
]

---
# .orange[What is **Machine Learning**]
  

.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt1[
  .left[
    A task (red box) requires an appropriate mapping - a model- from data described by feature to outputs. **Obtaining** such mapping from training data is what constitute a .orange[learning problem] (blue box).
  ]
  
  .tr[
    — _Machine Learning_ - Peter Flach, 2012
  ]
]



.left-column[
&lt;img src="img/PeterCartoon-square.jpg" width="100%" style="display: block; margin: auto;" /&gt;
]
.right-column[
&lt;img src="img/flach_learning_problem.png" width="100%" /&gt;
]



---
# .orange[Task]
  
A __task__ is something the ML must carry out

- the process of learning itself is not the task

- _Learning_ is the act of generate models having the ability to perform the task



&lt;br&gt;
&lt;br&gt;


A __task__ is defined in terms of _how the ML should process a collection of Examples_, i.e. a .orange[dataset].

---
# .orange[Task: Example]
  
  
&lt;small&gt;

**Learning Problem** | Task **T**  
---------------------|------------
Learning Checkers    | **Playing checkers**
Handwriting recognition | **Recognizing/Classifying handwritten words/numbers within images**
Self-driving car | **Driving from A to B**
Diseases extraction from EHR | **classify EHR by the disease reported (in free-text natural language)** 
Describe patient movement in bed | **At any given time provide position and dynamics of patients**

&lt;/small&gt;



---
# .orange[Performance]
  
A __performance__ is a quantitative measure for assessing the ability of ML

- performance is measured on the task being carried out

Usually __performance__ is measured in terms of:
  
- .orange[_accuracy_]: proportion of examples for which the model produces the correct output.

- .orange[_error rate_]: proportion of examples for which the model produces the incorrect output.

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
  

### .orange[**WARNING**: unbalanced data require balanced metrics!]
  
  
  
---
# .orange[Performance: Example]
  
&lt;small&gt;

**Learning Problem** | Task **T** | Performance **P** 
---------------------|------------|-------------------
Learning Checkers    | Playing checkers | **% games won **
Handwriting recognition | Recognizing/Classifying handwritten words/numbers within images | **% correctly classified words **
Self-driving car | Driving from A to B | **Average distance traveled before an error (as judged by humans)**
Diseases extraction from EHR | classify EHR by the disease reported (in free-text natural language) | **% of EHR correctly classified**
Describe patient movement in bed | At any given time provide position and dynamics of patients | **% average error in position or dynamics**

&lt;/small&gt;

---
#.orange[Experience]
  
.orange[__Experience__] is primarily determined by the amount of supervision during the learning process and the availability of labeled data


---
#.orange[Experience: Example]
  
&lt;small&gt;

**Learning Problem** | Task **T** | Performance **P** | Experience **E** 
---------------------|------------|-------------------|-----------------
Learning Checkers    | Playing checkers | % games won | **playing (against itself)**
Handwriting recognition | Recognizing/Classifying handwritten words/numbers within images | % correctly classified words | **process data sets of handwritten words with given classification**
Self-driving car | Driving from A to B | Average distance traveled before an error (as judged by humans) | **Sequence of videos, still images, and steering commands recorded while observing a human driver**
Diseases extraction from EHR | classify EHR by the disease reported (in free-text natural language) | % of EHR correctly classified | **process EHRs with given classification**
Describe patient movement in bed | At any given time provide position and dynamics of patients | % average error in position or dynamics | **time-series of patient kinetic measures taken from wearable devices and bed weight sensors, and position and dynamics collected by videos recorded observing inbed patients**

&lt;/small&gt;




---
# .orange[How do Machines **learn**?]
  
Machine learning is concerned with finding functions that **_best_ predict** outputs (responses), given data inputs (predictors)

`$$Y \simeq f(X)$$` 
  




&lt;img src="img/ml-process.png" width="60%" style="display: block; margin: auto;" /&gt;

.orange[_Learners_] are algorithms that improve their skills (in producing better models/functions) by learning from old/known .orange[__(training)__] data.

&lt;br&gt;
&lt;br&gt;

&gt; A .orange[_learner_] uses data and experience to perform better over time (i.e., producing new models that performs better than the previous ones)



---
# .orange[How do Machines **learn**?]
  
  
  
.left-code[
In traditional programming:
- **provide** an algorithm (a finite set of instructions)
- **provide** .orange[input] data (no training/new distinction)
- **obtain** the desired result.


In machine learning:
- **provide** the .orange[training] input (data)
- **provide** the .orange[training] known/desired result
- **obtain** the .orange[learning algorithm] (ingesting _new_ data and returning _new_ outputs).

Machine Learning problems are .orange[*optimisation*] ones.

]

.right-plot[
  
&lt;img src="img/MLvsTrad.png" width="100%" style="display: block; margin: auto;" /&gt;
]













---
# Types of .orange[learning]

#### .orange[Unsupervised] learning

&gt; The input data is _not labeled_ (there are not right answers!)

Data is given to the model, which is left to learn optimal .orange[patterns]/.orange[clusters].



#### (Passive) .orange[Supervised] learning

&gt; The learning algorithm is provided with a set of inputs along with the corresponding .orange[correct] outputs.

The algorithm compares its current inferred output with the correct one to learn from its .orange[errors] (i.e., to minimize it).


#### .orange[Active] learning

&gt; The learning algorithm .orange[interactively] queries a user (the _oracle_) to label new data with the desired (correct) outputs.

With input data labeled on the fly by .orange[oracle's knowledge], the model cycles query/train stages on the left unlabeled data.



---
# .orange[Basic **components**]

.orange[Training dataset]: data used as input to the learner to train the model

.orange[Validation dataset]: data used by the learner for validation and optimization

.orange[Training model]: the ML artifact that comes out of the training process

.orange[Cost (or loss) function]: a function to optimize in the ML system (sum of squared errors over the training data set)

.orange[Test dataset]: data provided to the trained model for performance estimations






---
class: middle, hide-count, inverse

# .center[.orange[Break]]

(Unordered) tips: 
- get up
- stretch
- look _far away_ (relax your eyes)
- hydrate
- go to the bathroom

<div class="countdown" id="timer_62900653" style="bottom:5%;left:65%;" data-audio="true" data-warnwhen="3">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>












---
class: inverse, middle, center, hide-count
# .orange[Classifiers]





---
class: middle center hide-count

&lt;img src="img/food.jpg" width="100%" style="display: block; margin: auto;" /&gt;



---
# .orange[Classification]
  
.left-code[
  __Feature space__
  
  - data: points in `\(\mathbb{R}^d\)`
    
    - dimensions:  scalar measurements
  
  &lt;br&gt;
    
    __Classifier functions (_classifiers_)__
  
  - a classifier for `\(K\)` classes is a function
  
  $$
    f:\mathbb{R}^d \to \{1, \ldots, K \}   
  $$
    - classifiers carve up the space into regions
]

.right-plot[
  
&lt;img src="img/classification_3.png" width="100%" style="display: block; margin: auto;" /&gt;
  
]




---
# .orange[Quantifying errors]

If `\(f\)` is our classifiers, i.e. for any given `\(x\)` we have `\(f(x) = \tilde{y}\)` is the predicted class (with `\(y\)` the real one), then

**Loss function** (for .orange[K] classes `\(\{1, \cdots, K\}\)`):

`$$\begin{split}\mathfrak{L}: \{1, \cdots, K\}&amp;\times \{1, \cdots, K\} &amp;\to [0, \infty)\\ (f(x)&amp;,\ y) &amp;\mapsto \mathfrak{L} (f(x),\ y)\end{split}$$`

&lt;br&gt;

&gt; If all mistakes are equally bad:
`$$\mathfrak{L}(i, j) = \begin{cases}
1 &amp; \textrm {if } i\neq j  \\
0 &amp; \textrm {if } i = j  \\
\end{cases}$$`

Note: if the outcome of `\(f\)` is a set of probabilities for the classes, the same definition is valid considering 
`$$\mathfrak{L}: \{p_1, \cdots, p_K\} \times \{1, \cdots, K\} \to [0, \infty)$$`


---
# .orange[Risk of classifier]
    
If the distribution of the classes is known, the .orange[risk] of classifier is the expected loss

$$
{\rm risk}(f) = \mathbb{E}[\mathfrak{L}(f(X), {\rm true\ class\ of\ } X)]
$$


We can evaluate the classifier by how large its risk is

&lt;br&gt;

&gt; The best way to possibly train a classifier is by **minimizing its risk**

&lt;br&gt;
&lt;br&gt;


&gt; N.B. The above one is a sort of common **_misuse of notation_**: a classifier is **.orange[a (single!) model]**, and **cannot be trained**!! when we say "train a model" the real meaning is 
.center[**"a MLT start producing models, somehow; new ones replacing the prevouses"**.]
Interpreting "replacement" like "modification", we can pretend that a (**.orange[single]**...) model is trained.
  


---
class: inverse, middle, center, hide-count
# .orange[Classifiers]

Main MLT examples

  
---
# .orange[Nearest neighbor]
  
.orange[__Idea:__] use training data itself as classifier

- Given: data point `\(x\)`
  
  - Find training data point closest to `\(x\)`
  
  - Assign `\(x\)` the label of closest point


---
#.orange[Nearest neighbor]

&lt;img src="img/knn.png" width="60%" style="display: block; margin: auto;" /&gt;

---
##.orange[Nearest neighbor (100 data points)]

&lt;img src="img/knn_2.png" width="60%" style="display: block; margin: auto;" /&gt;


---
class: inverse, middle, center, hide-count

# Your turn

.left[
How can we __train__ a model using a nearest neighbor MLT?

(i.e. what can be the _experience_?)
]

<div class="countdown" id="timer_629005ba" style="bottom:20%;left:70%;" data-audio="true" data-warnwhen="10">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>


---
# .orange[k-Nearest] Neighbor (kNN)

- Find `\(k\)` closest training points

- Take a majority vote between these points


&gt; .orange[__Rule of thumb:__] 3NN often works surprisingly well


---
##.orange[k-Nearest neighbor]

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/knn_k.png" alt="https://medium.com/analytics-vidhya/diabetes-classification-with-knn-and-logistic-regression-2edd3760a8c7" width="60%" /&gt;
&lt;p class="caption"&gt;https://medium.com/analytics-vidhya/diabetes-classification-with-knn-and-logistic-regression-2edd3760a8c7&lt;/p&gt;
&lt;/div&gt;


---
class: inverse, middle, center, hide-count

# Your turn

.left[
How can we __train__ a model using a k-nearest neighbor MLT?

(i.e. what can be the _experience_?)
]

<div class="countdown" id="timer_62900658" style="bottom:20%;left:70%;" data-audio="true" data-warnwhen="10">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, middle, center, hide-count

# Your turn

.left[
**Increasing** k, we provide **.orange[more or less] flexibility** to the model?

Which are the **minimum** and **maximum** possible k?
]

<div class="countdown" id="timer_629004cd" style="bottom:20%;left:70%;" data-audio="true" data-warnwhen="10">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>



---
#.orange[kNN: drawbacks]

In large dataset, finding nearest data points is expensive

Computational burden grows with dimension

&gt; it is the method of choice when dataset is small

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

__What to do for large dataset:__

- Extract a concise summary



---
# .orange[Linear classifiers] 

&lt;img src="img/linear_classifier_3.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Linear classifiers] 

&lt;img src="img/linear_classifier_5.png" width="70%" style="display: block; margin: auto;" /&gt;

.center[draw the convex hull]




---
#.orange[Linear classifiers:&lt;br&gt;Maximum margin hyperplane] 


&lt;img src="img/linear_classifier_6.png" width="70%" style="display: block; margin: auto;" /&gt;
  

.footnote[An hyperplane is a **subspace of co-dimension = 1** of a space (i.e. 1 dimension less then the space ones).

E.g., a line (1D) in a plane (2D); a plane (2D) in a 3D space; a 23D subspace in a 24D space.]

---
#.orange[Linear classifiers:&lt;br&gt;Maximum margin hyperplane]

&lt;br&gt;

&lt;img src="img/linear_classifier_7.png" width="70%" style="display: block; margin: auto;" /&gt;


---
#.orange[Linear classifiers: Support-Vector Machine] 


A maximum margin classifier is called __Support-Vector Machine__

Training a SVM is a .orange[convex] optimization problem

&gt; Empirically, SVM are among the most powerful (and fast) classifiers




---
# .orange[Limitations of linear classifiers]

.pull-left[
  
Problem 1: **curved optimal decision boundary**
  
  - SVM solves Problem 1 using the so-called .orange[_kernel trick_]

&lt;br&gt;
&lt;br&gt;
  
Problem 2: **classes may overlap**
  
- SVM solve Problem 2 by:
  
  - permitting .orange[misclassified] training points (**C** hyper-parameter)

  - each such point contributes a .orange[_cost_] to the optimization target function

  - using the .orange[kernel tricks]
  
]

.pull-right[
&lt;img src="img/classification_3.png" width="100%" style="display: block; margin: auto;" /&gt;
]




---
# .orange[Example of the kernel trick]

Suppose you have .orange[non-linearly separable] data



&lt;img src="img/kernel_1.png" width="70%" style="display: block; margin: auto;" /&gt;

&gt; Accuracy of classification given by the linear classifier: .orange[75%]




---
# .orange[Example of the kernel trick]

Project it into a three-dimensional space where the new coordinates are 

.left-column[
`$$\begin{cases}
X_1 &amp;= y_1^2 \\
X_2 &amp;= y_2^2 \\
X_3 &amp;= \sqrt{2}y_1y_2
\end{cases}$$`
]

.right-column[
&lt;img src="img/kernel.gif" width="90%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Example of the kernel trick]

Run the SVM on the trasformed data 

.right-column[
&lt;img src="img/kernel_2.gif" width="90%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Example of the kernel trick]

Now you got completely linearly separable data


&lt;img src="img/kernel_2.png" width="70%" style="display: block; margin: auto;" /&gt;

&gt; Accuracy of classification given by the SVM classifier: .orange[100%]




---
#.orange[Limitations of linear classifiers]

Problem 3: more than two classes 

- Can be addressed by combining multiple linear classifier

&lt;br&gt; 
&lt;br&gt; 

&gt; Some classifiers naturally apply to more classes, e.g., kNN.



---
class: inverse, middle, center, hide-count

# Your turn

.left[
The **C** parameter of SVMs MLTs determines the ammount of violation admitted, i.e. magnitude of data allowed to _cross the line_ (so, it cannot be negative).

C = 0 is "no violation admitted".

**Increasing** C, we provide **.orange[more or less] flexibility** to the model?
]

<div class="countdown" id="timer_629005ff" style="bottom:20%;left:70%;" data-audio="true" data-warnwhen="10">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>





---
# .orange[Ensemble classifiers]


__Weak classifier__

Consider two classes of equal size: assign class by coin flip: 50% expected error

&gt; weak classifier: .orange[error rate **slightly below** 50%]


__Ensemble Classifier__
- trains .orange[many _weak_] classifiers

- .orange[combines results] by majority vote

If weak classifiers are applicable to `\(k&gt;2\)` classes, so it is ensemble.



&lt;br&gt;&lt;br&gt;&lt;br&gt;

**Important examples: .orange[Random Forests]**




---
# .orange[Classification by majority vote]

`\(m\)` classifiers take a vote 

&gt; let us suppose `\(m\)` is an odd number

Two choices:
- correct = `\(1\)`
- wrong = `\(-1\)`

Decision is made by simple majority

- for two classes and classifiers `\(f_1,\ldots ,f_m\)` with output `\(\pm1\)`
majority vote at input `\(x\)` is
`$$\rm sgn \left( \sum_{j=1}^m f_j(x)\right)$$`





---
# .orange[Classification by majority vote]

Does the majority make the right choice?

.pull-left[
  Let's assume

-  each classifier makes the right choice with probability `\(p\in [0,1]\)`

- votes stochastilly independent when regarded as random outcomes
]


.pull-right[
.panelset[
&lt;img src="index_files/figure-html/unnamed-chunk-30-1.png" width="100%" style="display: block; margin: auto;" /&gt;

]
]
]




---
## .orange[Classification by majority vote]

&lt;img src="index_files/figure-html/unnamed-chunk-31-1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Weak learner: tree classifier]


&lt;img src="img/tree_1.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Weak learner: tree classifier]

&lt;img src="img/tree_2.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Weak learner: tree classifier]

&lt;img src="img/tree_3.png" width="70%" style="display: block; margin: auto;" /&gt;


---
# .orange[Weak learner: tree classifier]

&lt;img src="img/tree_4.png" width="70%" style="display: block; margin: auto;" /&gt;

---
# .orange[Weak learner: tree classifier]


.pull-left[
&lt;img src="img/tree_4.png" width="100%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/tree_5.png" width="100%" style="display: block; margin: auto;" /&gt;
]



---
# .orange[Random forest]
  
.orange[Tree training]: Input `\(n\)` training points of classes `\(1,\ldots, K\)`
  
- select `\(n\)` points uniformly at random with replacement

- train a tree on the randomized data set


.orange[For each tree]:
  
- in each step, select `\(m\)` axes at random (**mtry** hyper-parameter)

- compute best split point for each of these axes

- split along the one that minimizes error


&gt; .orange[Train **ntree** trees in total]
&gt;  - compute class label of new point `\(x\)` under each of the **ntree** trees
&gt;  - take majority vote




---
#.orange[Hyperplane comparison]


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/hyperplane.png" alt="2 classes classification" width="70%" /&gt;
&lt;p class="caption"&gt;2 classes classification&lt;/p&gt;
&lt;/div&gt;

---
#.orange[Hyperplane comparison]

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/hyperplane_2.png" alt="Hyperplane for XOR pattern" width="65%" /&gt;
&lt;p class="caption"&gt;Hyperplane for XOR pattern&lt;/p&gt;
&lt;/div&gt;





---
class: inverse, middle, center, hide-count

# Your turn

.left[
The **mtry** parameter of RF MLTs determines how many variables are randomly selected to train each tree.

- **Increasing** mtry, we provide **.orange[more or less] flexibility** to the model?
- Which are the **minimum** and **maximum** possible mtry?

The **ntree** parameter of RF MLTs determines how many trees there are in the forest (i.e., you are going to train).

- What is the effect of **increasing** ntree?

]

<div class="countdown" id="timer_6290052b" style="bottom:15%;left:70%;" data-audio="true" data-warnwhen="10">
<code class="countdown-time"><span class="countdown-digits minutes">01</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>




---
class: middle, hide-count, inverse

# .center[.orange[Break]]

(Unordered) tips: 
- get up
- stretch
- look _far away_ (relax your eyes)
- hydrate
- go to the bathroom

<div class="countdown" id="timer_62900513" style="bottom:5%;left:65%;" data-audio="true" data-warnwhen="3">
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>










---
class: inverse, middle, center, hide-count
# .orange[Model selection]



---
# .orange[Error for a classifier]


.orange[Training error] for a classifier:

`$$\rm Training\ error = \frac{no\ of\ miclassified\ training\ points}{no\ of\ training\ points}$$`



.orange[Prediction error] for a classifier

  - harder to define: with respect to which distribution?
  
  - ideally the distribution of the underlying data source

`$$\rm Prediction\ error = \mathbb{E}(proportion\ of\ misclassified\ points)$$`

&lt;br&gt;
&lt;br&gt;

Assuming all error costs the same: .orange[ __prediction error__] is the risk



---
# .orange[Overfitting]


Sample data acts as proxy for underlying data source

.orange[_Overfitting_] means adapting too closely to the idiosyncrasies of a sample set

&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;

**Result**: Small error on training data but .orange[poor predictive performance]!




---
class: center, middle, hide-count

&lt;img src="img/overfit.jpg" width="100%" style="display: block; margin: auto;" /&gt;



---
# .orange[Parameters]

.orange[Tree classifier]

  - Number of splits

&lt;br&gt;

.orange[Tree ensemble]

  - tree parameters

  - number of trees

&lt;br&gt;


.orange[Random forest]

  - tree parameters

  - number of trees

  - number of random dimensions


---
#.orange[Parameters Vs. hyper-parameters]

&lt;img src="img/overfitting_5.png" width="90%" style="display: block; margin: auto;" /&gt;



---
# .orange[Terminology]

&gt; Example: Tree

&lt;br&gt;
&lt;br&gt;

__Model:__  Family of classifiers

- All trees with `\(k\)` splits

&lt;br&gt;

__Parameter__  Indexes different classifiers within model

  - Split locations

&lt;br&gt;
  
__Hyperparameter__  Indexes different  models

  - `\(k\)`


---
# .orange[Overfitting]

Model is .orange[not able to generalize]

Learn the data and .orange[not the underlying function]

Performs well on training data but .orange[poorly with new data]

&lt;br&gt;

&lt;img src="img/figure3.png" width="90%" style="display: block; margin: auto;" /&gt;



---
# .orange[Overfitting: example ]

Two alternative models of human papillomavirus infection and its progression to cervical cancer (CIN) 

The complex model includes multiple stages of pre-cancerous lesions which can progress or regress at different rates (model parameters) 

&lt;br&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/Figure_8.png" alt="Basu 2013" width="100%" /&gt;
&lt;p class="caption"&gt;Basu 2013&lt;/p&gt;
&lt;/div&gt;


---
# .orange[Overfitting ]

Prevalence data of (CIN) generated using more complex model over a 30-year period among a fictional cohort of young women

The complex model (in green) actually has a better .orange[_fit_] to the early prevalence data (solid red dots) than does the simpler model (in blue)...

However, the complex model produced a pattern that poorly forecasts future prevalence (hollow red dots)


&lt;img src="img/Figure_9.png" width="60%" style="display: block; margin: auto;" /&gt;


---
# .orange[Overfitting]

Every additional parameter in the model introduces new sources of uncertainty and potential to affect results in non-intuitive ways that may either be useful or deceptive

Complex models must be well-characterized in terms of their behavior before they are used for .orange[__forecasting__ ]


---
#.orange[Cross-validation]

&gt; How to select an adequate model based on sample data?


.orange[__Recall__]: model selection chooses a model complexity (hyperparameter)
  
  - Training a classifiers chooses parameter values
  
  - The training can often be formulated as minimizing the training error

&lt;br&gt;
&lt;br&gt;

.orange[Model selection cannot be performed by minimizing the training error]

  - it would lead to overfitting




---
# .orange[Cross-validation]


&gt; How to select an adequate model based on sample data?



.orange[**Recall**]: we use sample data as proxy for actual data source
   
  - ask how to select a model if the underlying distribution was known

  - apply sample principle

  - approximate data source by sample data

&lt;br&gt;
&lt;br&gt;


This is called .orange[__cross-validation__ ]

---
# .orange[Cross-validation]

If we knew underlying distribution
  
  - train classifiers with .orange[different hyperparameters] on training data
  
  - compute prediction errors under true distribution
  
  - choose the one with .orange[smallest prediction error]

&lt;br&gt;


.orange[Separating model selection and training] prevents overfitting

&lt;br&gt;

Approximation of actual data source by sample data


  -  split training data set
  
  -  train on set 1
  
  -  test predictive performance on set 2




---
# .orange[Cross-validation]

Data splitting estimates the .orange[predicion error from data]

&lt;br&gt;

Prediction error estimates can be used in two ways

  - model selection `\(\Leftrightarrow\)` .orange[optimize] performance

  - classifier assessment `\(\Leftrightarrow\)` .orange[interpret] performance (estimates the prediction error of the final choice of classifier)


&lt;br&gt;
&lt;br&gt;


.orange[We must not use the] .red[same data for both]


---
# .orange[Cross-validation]

1. Split data into three sets

  a. training set
  
  b. validation set
  
  c. test set (hold out set)


2. Train classifiers with .orange[different hyperparameters] on training set

3. Select that with smallest .orange[prediction error on validation set]

4. Estimate .orange[performance on test set]

&lt;br&gt;

.orange[Separate test set is crucial]:

  - prediction error estimate on validation set is confounded by model selection





---
# .orange[Cross validation: how to split the data]

If samples assumed i.i.d., split at random

  - sampling w/o replacement
  
&lt;br&gt;

Remaining question: .orange[how large] should be each set be?


&lt;br&gt;

Advantages of different choices

  - Large training set `\(\Leftrightarrow\)` .orange[more accurate] classifier
  
  - Small training set `\(\Leftrightarrow\)` .orange[reflects variation] between sample sets



---
# .orange[Leave-one-out cross-validation]


For every data point `\(x_i,\ i = 1, \ldots, n\)`:

  - train the model on every point except the single point `\(X_i\)`,
  
  - compute the validation error on the held out point


&lt;br&gt;

Average the test error


---
class: hide-count
# .orange[Leave-one-out cross-validation]

&lt;img src="img/cv_1.png" width="90%" style="display: block; margin: auto;" /&gt;


---
class: hide-count
# .orange[Leave-one-out cross-validation]

&lt;img src="img/cv_2.png" width="90%" style="display: block; margin: auto;" /&gt;



---
#.orange[K-fold cross validation]


0. .orange[Remove test set] and set it aside

1. Divide remaining data into `\(K\)` .orange[equally sized] blocks

2. Cross-validate: for `\(k = 1,\ldots, K\)`

  - remove block `\(k\)` from training data
  
  - train classifier on remaining bloks.
  
  - estimate prediction error on block `\(k\)`
  
3. Estimates over all `\(k\)` and select best classifier

4. When classifier is chosen, estimate its performance .orange[on test set]



---
# .orange[K-fold cross validation]

The misclassification error rate is computed on the observations in the held-out fold. 

&lt;img src="img/Cv1.png" width="100%" style="display: block; margin: auto;" /&gt;




---
# .orange[K-fold cross validation]

This procedure is .orange[repeated K] times; each time, a different group of observations is treated as a validation set.


&lt;img src="img/Cv2.png" width="100%" style="display: block; margin: auto;" /&gt;

---
# .orange[K-fold cross validation]

The .orange[CV error rate] is then calculated as the average of these K error rates.


&lt;img src="img/Cv3.png" width="100%" style="display: block; margin: auto;" /&gt;


---
# .orange[K-fold cross validation: how many folds?]

&lt;img src="img/splits.png" width="100%" style="display: block; margin: auto;" /&gt;

Generally, .orange[k between 5 and 10] avoids over-training the model (variance), whilst avoiding too few training points (bias)



---
# .orange[Bias and Variance trade-off]

In order to minimise test error on new data points, statistical theory (out of the scope of this workshop) tells us that we need to select a function that achieves .orange[*low variance*] and .orange[*low bias*].


 - .orange[**Variance**] refers to the amount by which our predictions would **change if we estimated using a different training set**. 
   &gt; The more flexible the model, the higher the variance.

 - .orange[**Bias**] refers to the **error that introduced by the approximation** we are making with our model (represent complicated data by a simple model). 
   &gt; The more simple the model, the higher the bias.

There is a .orange[trade off] between increasing variance (flexibility) and decreasing bias (simplicity) and vice versa.

&lt;img src="img/tradeoff.png" width="40%" style="display: block; margin: auto;" /&gt;


---
class: hide-count
#.orange[Bias variance trade-off]


The bias-variance trade-off concerns the generalizability of a trained predictor in light of new data points

If a predictor has high bias and/or high variance, it will not do well in predicting on new data

&lt;img src="img/BV.png" width="60%" style="display: block; margin: auto;" /&gt;


Good, generalizable predictors need to have .orange[both low bias and low variance]



---
#.orange[Summary]




Cross-validation .orange[selects model] and .orange[assess classifier]

  - Both require estimate the prediction error


Estimates are obtained from .orange[separate training and test data sets]


Assessment must use .orange[separate validation] set

  - otherwise classifier ability is systematically overestimated

&lt;br&gt;

To interpret machine learning results

  - ask yourself: .orange[did the researchers who trained the model have access to validation data?]

  &gt; .orange[**if so, results could be possibly confounded.**]












---
class: inverse, middle, center, hide-count
# .orange[A tour of Machine Learning algorithms&lt;br&gt;in healthcare]






---
# .orange[ML algorithms]

Hundreds new algorithms every year

More than 100 Wikipedia pages on specific ML algorithms

&gt; many of them are variation on a few major classes

---
# .orange[Classifier]

Does data belong to class A? .orange[_is this really a heart failure patient?_]

&lt;br&gt;

Classifiers are the most commonly used ML algorithms in analytics applications


  -  Suggest possible patient diagnoses

  - Identify patients with high readmission risk

  - Automatically alert care providers early in the development of sepsis

  - Define the threshods for _abnormal_ lab results

  - Automatically differentiate between clinical and administrative documents

  - Recommend the most effective wellness or disease management intervention for a patient

  -  many, many more...

---
# .orange[Classifiers: logistic regression]


.orange[__Logistic regression__] is the workhorse of classifers


  - it uses a single, straight cut to divide the world of possible features into two groups
    
`$$\ln\left(\frac{p}{1-p} \right) = \beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p$$`


---
# .orange[Classifiers: Support Vector Machine]

.orange[**SVM**] is a linear classifier with a twist

The world of possible features is split by a single line as in logistic regression, but .orange[this line can be curved]. 

This additional flexibility makes SVM highly adaptable

&gt; Because of the way the curvature is introduced (though a _kernel_), SVM are still .orange[simple to compute and interpret].


---
# .orange[Classifiers: decision trees]

Family of algorithms, all based on the idea of creating a tree of decisions about features that lead to a specific classification

  - Is ejection fraction above or below 50?
  
  - to identify heart failure, the algorithm may start with ejection fraction 


For each of these paths, a new question is considered

  - does the echocardiogram show Left Ventricle Hypertrophy?

&lt;br&gt;

At the end of each series of questions the patient falls into either a .orange[heart failure] or a .orange[not heart failure] diagnosis (bucket)

---
class: hide-count
# .orange[Classifiers: decision trees]

&lt;img src="img/figure_6.png" width="100%" style="display: block; margin: auto;" /&gt;

---
# .orange[Classifiers: random forest]

Improves upon decision trees by dividing the input data into .orange[many different subsets] and creating a different decision tree for each of them
  - All of the different resulting decision trees then .orange[vote] to determine the final classification of the input

&lt;br&gt;

Reduces the risk of making the final buckets too small and subsequently being fooled by random variations in the original labeled training data




---
# .orange[Classifiers: Neural Networks] 

(Naive) .orange[__definition:__] An Artificial Neural Network is an information processing paradigm that is inspired by the way biological nervous systems process information:

  - A large number of highly interconnected simple processing elements (neurons) working together to solve specific problems



---
# .orange[Classifiers: Neural Networks] 

.pull-left[

- an .orange[input layer] of neurons
- one or more .orange[hidden layers]
- an .orange[output layer]

&lt;br&gt;

- Each internal node receives inputs from other units
- A weight `\(w\)` is associated to each input
- The unit computes a function of the weighted sum of its inputs
- Outputs are compared with target to compute the value of some predefined error function
- The error is feedback through the network
  - the algorithm adjust the weights of each connection to reduce the value of the error function
]


.pull-right[
&lt;img src="img/nn_1.png" width="70%" style="display: block; margin: auto;" /&gt;

&lt;img src="img/nn_2.png" width="70%" style="display: block; margin: auto;" /&gt;
]




---
# .orange[Clustering]

Can the data be grouped into natural categories or buckets?

.orange[_Are there natural groupings that can help me understand my patients?_]


---
# .orange[Clustering: Unsupervised]

  - Can automatically identify naturally occurring groups of similar items
  
  &gt; E.g., .orange[K-Means]: the algorithm is given a set of attributes and a number of clusters to create

  - the algorithm works out which combinations of attributes most accurately divide the items into that number of groups 

  - attributes: for example, diagnoses and lab measurements


&lt;br&gt;
&lt;br&gt;

 &gt; resulting _clusters_ are .orange[interpreted by humans] by looking at
which attributes are most important in the cluster



---
# .orange[Clustering: Hierarchical]


Creates a tree or dendogram of clustering scenarios for data

  - starts creating a single cluster containing all the items

  - splits into two clusters, each of which further splits into two clusters, `\(\ldots\)`  until each cluster contains only a single item. 

  - the process can be stopped at any point to create meaningful clusters



---
# .orange[Clustering: examples]


.orange[__Risk adjustement__]

  - when calculating the impacts of different treatments, the baseline level of illness for each patient needs to be computed to create a consistent baseline for comparison of methods across all patients 

  - Clustering can be used to group patients into meaningful groups of similar comorbidities or risks

&lt;br&gt;
&lt;br&gt;

.orange[__Patients like mine__]

  - In the care of complex or rare disease, understanding how different treatments have worked on other patients in similar situations

  - Identifyimg subtype of disease

  - Clustering can be very useful to identify the most similar patients.













---
class: inverse, middle, center, hide-count
# .orange[ Best practices for implementing&lt;br&gt;Machine Learning]





---
# .orange[Ask a Specific Question]

ML algorithm should answer a .orange[very specific question]

The best first question is something already known to have a reference and some intuition to compare results with




---
# .orange[Start simple]

.orange[Keep it simple] both for model selection and data for your analysis

  - start with the minimal set of data that could get you to a good result


&lt;br&gt;


.orange[Keep robustness]

  - less model complexity and fewer parameters are always beneficial 


&lt;br&gt;

&gt; .orange[Start quickly and simple, and next iterate!]



---
# .orange[Try Many Algorithms]

Try a few different algorithms to see how they work


If one classifier works incredibly well and another doesn't seem to work well at all, .orange[be cautious]

- maybe overfitting situation, not really have much predictive power 


.orange[Combine methods]

The better your features, the better your performance will be

Data is more important than the exact algorithm you use  

- more training data is always desirable. 

&lt;br&gt;
  
  &gt; .orange[start with SVM or RF (or even with simple linear regression!)]



---
# .orange[Treat data with suspicious]
  
  Look at the data 

- dig into its details 

- look for correlations

- systematic biases, errors, and flaws


&lt;br&gt;
  &lt;br&gt;
  
  .orange[Normalize] input data 

- ML algorithms can perform .orange[poorly and slowly] if there are large differences in scale between different features



---
# .orange[Validate your Model]
  
  Separate your data into .orange[training, validation, and test sets]

- if you are using K-fold cross validation, at least hold out a test set 

&lt;br&gt;
  &lt;br&gt;
  &lt;br&gt;
  
  &gt; .orange[If you take ANY decision after having seen a performance on a data set, it becomes a training one (even if you have treated it as a test)]


---
# .orange[Healthcare does not trust black boxes]
  
  Some ML methods are more transparent than others    

- Clustering, tend to be easy to interpret, because they create groupings of concepts      

- Linear regression can tell how important each feature is to the final output 


&lt;br&gt;
  
  Random forests are .orange[difficult to interpret]. 

Neural networks, deep learning are .orange[truly black boxes]

- very little transparency to what is important in the decision making process



---
# .orange[Monitoring ongoing performance &amp; keep track of model changes] 
  
  Check your results against incoming new data 

- monitor data and algorithm statistics with a dashboard

&lt;br&gt;
  
  .orange[Track the revision of your model] along with data analytics pipeline



---
# .orange[Do not be fooled by Accuracy]
  
  While looking for a rare event that only happens 1% of the time,  you can report your accuracy as 99% 
  
  - meaningless 

&lt;br&gt;
  
  Before starting a project, better figure out which precision and recall application requires to be useful

&gt; - .orange[Build the model with these metrics on your mind]
&gt; - .orange[Use balanced metrics]


---
class: inverse, center, middle, hide-count
# Thanks!
# <span>&lt;i class="fas  fa-thumbs-up fa-5x faa-float animated "&gt;&lt;/i&gt;</span>

&lt;br&gt;
  
  .right[
    [<span>&lt;i class="fas  fa-envelope faa-passing animated "&gt;&lt;/i&gt;</span>](mailto:corrado.lanera@ubep.unipd.it) [corrado.lanera@ubep.unipd.it](mailto:corrado.lanera@ubep.unipd.it)
    
    [<span>&lt;i class="fas  fa-calendar-check faa-flash animated "&gt;&lt;/i&gt;</span>](https://calendly.com/corradolanera) [calendly.com/corradolanera](https://calendly.com/corradolanera)
    
  ]






---
class: hide-count
# .orange[Outline **.orange[A]**]

- Topic **one**

- Second **topic**

- Another **interesting** topic




---
class: inverse, middle, center, hide-count
# .orange[Topic **one**]
 

---
# Foo


---
class: inverse, middle, center, hide-count
# .orange[Second **topic**]
 

---
# Bar



---
class: inverse, middle, center, hide-count
# .orange[Another **interesting** topic]
 
 
---
# Tar










.panelset[
.panel[.panel-name[XXXXX]
foo
]
.panel[.panel-name[XXXXX]
bar
]
]
<div class="countdown" id="timer_629004cb" style="bottom:20%;left:70%;" data-audio="true" data-warnwhen="3">
<code class="countdown-time"><span class="countdown-digits minutes">15</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>



&lt;div class="figure"&gt;
&lt;img src="img/UBEP.png" alt="https://www.unipd-ubep.it/" width="80%" /&gt;
&lt;p class="caption"&gt;https://www.unipd-ubep.it/&lt;/p&gt;
&lt;/div&gt;













---
class: inverse
# Risorse utili













---
class: inverse, center, middle, hide-count


.bg-washed-green.b--dark-green.ba.bw2.br3.shadow-5.ph4.mt5[
.left[
_If you think the only acceptable performance is the ".orange[perfect performance]",&lt;br&gt;AI is not for you!&lt;br&gt;But, I've heard that even humans have made mistakes..._
]

.tr[
— Daniel Oberski&lt;br&gt;2021/03/26 ASReview interview&lt;br&gt;https://daob.nl/
]
]

&lt;br&gt;
# Thank .orange[you] for the attention!


&lt;br&gt;
&lt;br&gt;

Slides: &lt;SLIDES' URL&gt;


[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg>](https://www.unipd-ubep.it/) [**www.unipd-ubep.it**](https://www.unipd-ubep.it/) | 
[<svg aria-hidden="true" role="img" viewBox="0 0 576 512" style="height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M160 448c-25.6 0-51.2-22.4-64-32-64-44.8-83.2-60.8-96-70.4V480c0 17.67 14.33 32 32 32h256c17.67 0 32-14.33 32-32V345.6c-12.8 9.6-32 25.6-96 70.4-12.8 9.6-38.4 32-64 32zm128-192H32c-17.67 0-32 14.33-32 32v16c25.6 19.2 22.4 19.2 115.2 86.4 9.6 6.4 28.8 25.6 44.8 25.6s35.2-19.2 44.8-22.4c92.8-67.2 89.6-67.2 115.2-86.4V288c0-17.67-14.33-32-32-32zm256-96H224c-17.67 0-32 14.33-32 32v32h96c33.21 0 60.59 25.42 63.71 57.82l.29-.22V416h192c17.67 0 32-14.33 32-32V192c0-17.67-14.33-32-32-32zm-32 128h-64v-64h64v64zm-352-96c0-35.29 28.71-64 64-64h224V32c0-17.67-14.33-32-32-32H96C78.33 0 64 14.33 64 32v192h96v-32z"/></svg>](mailto:Corrado.Lanera@ubep.unipd.it) [**Corrado.Lanera@ubep.unipd.it**](mailto:Corrado.Lanera@ubep.unipd.it)

[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>](https://twitter.com/corradolanera)
[<svg aria-hidden="true" role="img" viewBox="0 0 448 512" style="height:1em;width:0.88em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z"/></svg>](https://telegram.me/CorradoLanera)
**@CorradoLanera** | 
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:currentColor;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>](https://github.com/UBESP-DCTV)
**@UBESP-DCTV**


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
